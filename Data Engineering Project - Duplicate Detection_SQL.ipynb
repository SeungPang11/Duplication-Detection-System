{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8b7a3f-61e6-4dc7-8f0f-4fb2eae6b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate Detection\n",
    "\n",
    "#Minhash/LSH algorithm to detect 10 most similar entries in articles1.csv to a reference article. \n",
    "#The reference article is in the dataset, identified as Article ID 69716, \n",
    "#The Minhash/LSH algorithm relies on the concept of distances to define similarity. \n",
    "#For this project, Jaccard similarity is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f1c876c-06a1-42d0-8586-c56732779df5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/seungpang/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /Users/seungpang/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from pyspark) (0.10.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install tools\n",
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04101110-5e28-4f61-be44-0273017c3a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasketch in /Users/seungpang/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (1.5.9)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/seungpang/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from datasketch) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/seungpang/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from datasketch) (1.24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e052870-a2a6-4c7f-a2c0-84d4ea4f4caa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/02 17:59:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/02 17:59:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/04/02 17:59:28 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/04/02 17:59:28 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "23/04/02 17:59:28 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://seungui-mbp:4044\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9209529cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create spark context\n",
    "import os\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf()\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cd7a203-04d1-44bd-8e5a-77a2a791f120",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "data = spark.read.format(\"csv\")\\\n",
    "        .option(\"inferSchema\", \"true\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .load(\"articles1.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75aeff79-aef6-4411-8f98-7764470265a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "692ee689-4d9f-42b7-8823-334a0296e821",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- publication: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92836639-761f-4f3c-98ca-89b5b907f9ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasketch import MinHash\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c08953-8686-4c16-9ecd-dddb686d1c65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/02 17:59:36 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , id, title, publication, author, date, year, month, url, content\n",
      " Schema: _c0, id, title, publication, author, date, year, month, url, content\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/seungpang/Desktop/Big%20Data%20Midterm/articles1.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_c0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>None</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _c0     id                                              title  \\\n",
       "0   0  17283  House Republicans Fret About Winning Their Hea...   \n",
       "\n",
       "      publication      author        date    year month   url  \\\n",
       "0  New York Times  Carl Hulse  2016-12-31  2016.0  12.0  None   \n",
       "\n",
       "                                             content  \n",
       "0  WASHINGTON  —   Congressional Republicans have...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "262ab3f0-4148-4278-ad58-8dc96fb87413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|   id|               title|             content|\n",
      "+-----+--------------------+--------------------+\n",
      "|69716|California lifted...|’’ ’On Wednesday,...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View reference data\n",
    "\n",
    "# Article ID 69716, \n",
    "# “California lifted its mandatory water restrictions - \n",
    "# that could be a huge mistake”\n",
    "spark.sql(\"SELECT id, title, content \\\n",
    "        FROM dfTable \\\n",
    "        WHERE id = 69716\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f05e98b2-1b0b-4933-b4de-063eca32084f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark-nlp in /Users/seungpang/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (4.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install NLP package for text preprocessing\n",
    "pip install spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e846308-b0b8-498d-9b43-251e0786846e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/seungpang/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/seungpang/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: tqdm in /Users/seungpang/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /Users/seungpang/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/seungpang/Library/jupyterlab-desktop/jlab_server/lib/python3.8/site-packages (from nltk) (2023.3.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ee3d77-075d-42fe-8dac-7536c515f490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8759a00-592b-454c-b475-0117afea61d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|   id|               title|             content|\n",
      "+-----+--------------------+--------------------+\n",
      "|17283|House Republicans...|WASHINGTON  —   C...|\n",
      "|17284|Rift Between Offi...|After the bullet ...|\n",
      "|17285|Tyrus Wong, ‘Bamb...|When Walt Disney’...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Select relevant columns\n",
    "data1 = data.select('id', 'title', 'content')\n",
    "data1.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0ff9ac8-1f15-4617-b033-fd19f764793e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.createOrReplaceTempView(\"dfTable1\")\n",
    "data1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c811b6a2-c2a8-44b0-8790-2f37104f1924",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50004"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total 50004 rows\n",
    "data1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a63cfa-4ec9-410b-8e74-223f197b8283",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+\n",
      "|                  id|               title|content|\n",
      "+--------------------+--------------------+-------+\n",
      "|               28110|\"UK Jobs Market C...|   null|\n",
      "|               30419|\"Cohn: Trump Beco...|   null|\n",
      "|               33070|\"Facebook \"\"Fake ...|   null|\n",
      "|               46670|\"DePaul Protester...|   null|\n",
      "|               48580|Politico Scoop: D...|   null|\n",
      "|               66261|                   \"|   null|\n",
      "| our Whole Foods ...| after we account...|   null|\n",
      "|               71949|                   \"|   null|\n",
      "|               72340|                   \"|   null|\n",
      "+--------------------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "from pyspark.sql.functions import col\n",
    "data1.filter(data1.content.isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e1868d9-cd22-49e3-a1b2-f82042f2471f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49995"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop null rows - 49995 rows after \n",
    "data1 = data1.na.drop()\n",
    "data1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80e42d70-efc2-4bdd-81f8-2dcf0ece66ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1.createOrReplaceTempView(\"dfTable1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d52d8389-b790-425b-b1d5-77d83fdb3b48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess Text\n",
    "# https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.Tokenizer.html\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "# regexTokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"content\", outputCol=\"regex\", pattern=\"\\\\W\")\n",
    "\n",
    "regexTokenized = regexTokenizer.transform(data1)\n",
    "# regexTokenized.select(\"regex\") \\\n",
    "#     .withColumn(\"tokens\", countTokens(col(\"regex\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd60ad4e-dd61-4862-8641-80431bae3454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a15b118-dfd2-40a7-a26e-5edff7b2a910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "# https://spark.apache.org/docs/latest/ml-features#tokenizer\n",
    "remover = StopWordsRemover(inputCol=\"regex\", outputCol=\"stop_words\")\n",
    "clean_df = remover.transform(regexTokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "783a8e64-73d8-4e2e-bd05-4d00f7388fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|   id|               title|             content|               regex|          stop_words|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|17283|House Republicans...|WASHINGTON  —   C...|[washington, cong...|[washington, cong...|\n",
      "|17284|Rift Between Offi...|After the bullet ...|[after, the, bull...|[bullet, shells, ...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clean_df contains preprossed text\n",
    "clean_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8349831a-592c-4e41-8bce-c4b0bc6772ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only get id, and stop_words column\n",
    "final_df = clean_df.select('id', 'stop_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5396eed9-f971-475a-9034-74ba65b5a85d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|   id|          stop_words|\n",
      "+-----+--------------------+\n",
      "|17283|[washington, cong...|\n",
      "|17284|[bullet, shells, ...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d57ef081-8426-4457-a744-8ceb07c625a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------------------+\n",
      "|   id|content|               title|\n",
      "+-----+-------+--------------------+\n",
      "|60381|       |Wonders of the un...|\n",
      "|60745|       |The week in 32 ph...|\n",
      "|63359|       |Enchanting waterf...|\n",
      "+-----+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT id, content, title \\\n",
    "        FROM dfTable \\\n",
    "        WHERE content = ' '\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a59f5f68-421a-4eeb-a6f7-36e390f78940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c409786-b3a4-4e28-951d-4de36c52971d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/converting-a-pyspark-dataframe-column-to-a-python-list/\n",
    "# ref - is the reference article\n",
    "ref = clean_df.select('stop_words').where(clean_df.id == 69716).rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# final_df to flatMap\n",
    "d = final_df.rdd.flatMap(lambda x: [x]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6998dceb-ebd2-4a01-b0bf-6037fc170077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasketch import MinHash\n",
    "from datasketch import MinHashLSH\n",
    "from pyspark.sql.functions import encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae0dd1f9-6fce-42d3-969b-53ec0515f5be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Use MinHash and Compute Jaccard Similarty score\n",
    "m1, m2 = MinHash(), MinHash()\n",
    "jacard = []\n",
    "\n",
    "# Reference article\n",
    "# for j in ref[0]: \n",
    "#     m1.update(j.encode('utf8'))\n",
    "s1 = set(ref[0])\n",
    "\n",
    "jaccard = []\n",
    "# ind 0 to 49994\n",
    "for i in range(0, len(d)):\n",
    "    # for d in d[i][1]:\n",
    "    #     m2.update(d.encode('utf8'))\n",
    "        \n",
    "    s2 = set(d[i][1])\n",
    "    actual_jaccard = float(len(s1.intersection(s2)))/float(len(s1.union(s2)))\n",
    "    # print(\"Actual Jaccard for ref_article and data is\", actual_jaccard)\n",
    "    jaccard.append(actual_jaccard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6927532f-5aa3-4a5a-9b7a-31b98269e03c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             Jaccard|\n",
      "+--------------------+\n",
      "| 0.06276747503566334|\n",
      "| 0.07883026064844247|\n",
      "|               0.075|\n",
      "|  0.0585480093676815|\n",
      "| 0.05901116427432217|\n",
      "|               0.025|\n",
      "|0.052547770700636945|\n",
      "|  0.0922165820642978|\n",
      "|  0.0673076923076923|\n",
      "| 0.05611510791366906|\n",
      "| 0.09114249037227215|\n",
      "|  0.0859538784067086|\n",
      "| 0.05646036916395222|\n",
      "| 0.08774834437086093|\n",
      "| 0.07119741100323625|\n",
      "| 0.07622298065984073|\n",
      "| 0.07158590308370044|\n",
      "| 0.07328072153325817|\n",
      "| 0.05132192846034215|\n",
      "| 0.03177570093457944|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert jaccard list to dataframe\n",
    "jcrd = spark.createDataFrame([(l,) for l in jaccard], ['Jaccard'])\n",
    "jcrd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd23830b-852c-42da-a28a-0386a91d4c75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df = final_df.withColumn(\"id\", final_df[\"id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f02c771-9939-45e3-8ac3-e878b216731a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- stop_words: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c8979a0-b693-4251-b704-f5d57223c81e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                  _1| _2|\n",
      "+--------------------+---+\n",
      "|{17283, [washingt...|  0|\n",
      "|{17284, [bullet, ...|  1|\n",
      "|{17285, [walt, di...|  2|\n",
      "|{17286, [death, m...|  3|\n",
      "|{17287, [seoul, s...|  4|\n",
      "|{17288, [london, ...|  5|\n",
      "|{17289, [beijing,...|  6|\n",
      "|{17290, [danny, c...|  7|\n",
      "|{17291, [hillary,...|  8|\n",
      "|{17292, [angels, ...|  9|\n",
      "|{17293, [donald, ...| 10|\n",
      "|{17294, [thompson...| 11|\n",
      "|{17295, [west, pa...| 12|\n",
      "|{17296, [article,...| 13|\n",
      "|{17297, [season, ...| 14|\n",
      "|{17298, [finally,...| 15|\n",
      "|{17300, [pages, j...| 16|\n",
      "|{17301, [mumbai, ...| 17|\n",
      "|{17302, [baghdad,...| 18|\n",
      "|{17303, [sydney, ...| 19|\n",
      "+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ID and pre-processed text, indexed\n",
    "data_df = data_df.rdd.zipWithIndex()\n",
    "data_df = data_df.toDF()\n",
    "data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "637acdaf-9eec-41cd-a37c-6a71a4b21971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df = data_df.select(data_df._1.getItem('id').alias('ID'), data_df._1.getItem('stop_words').alias('Content'), data_df._2.alias('Ind'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5637935f-c64d-4511-a42d-b5634cab851e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---+\n",
      "|   ID|             Content|Ind|\n",
      "+-----+--------------------+---+\n",
      "|17283|[washington, cong...|  0|\n",
      "|17284|[bullet, shells, ...|  1|\n",
      "|17285|[walt, disney, ba...|  2|\n",
      "+-----+--------------------+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "087953c2-eda4-4216-aa85-6b80ee7268f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---+-----------+\n",
      "|   ID|             Content|Ind|    Jaccard|\n",
      "+-----+--------------------+---+-----------+\n",
      "|17283|[washington, cong...|  0|0.062767476|\n",
      "|17284|[bullet, shells, ...|  1| 0.07883026|\n",
      "|17285|[walt, disney, ba...|  2|      0.075|\n",
      "|17286|[death, may, grea...|  3| 0.05854801|\n",
      "|17287|[seoul, south, ko...|  4|0.059011165|\n",
      "|17288|[london, queen, e...|  5|      0.025|\n",
      "|17289|[beijing, preside...|  6| 0.05254777|\n",
      "|17290|[danny, cahill, s...|  7| 0.09221658|\n",
      "|17291|[hillary, kerr, f...|  8|0.067307696|\n",
      "|17292|[angels, everywhe...|  9| 0.05611511|\n",
      "|17293|[donald, j, trump...| 10| 0.09114249|\n",
      "|17294|[thompsons, tex, ...| 11| 0.08595388|\n",
      "|17295|[west, palm, beac...| 12| 0.05646037|\n",
      "|17296|[article, part, s...| 13| 0.08774834|\n",
      "|17297|[season, family, ...| 14| 0.07119741|\n",
      "|17298|[finally, second,...| 15| 0.07622298|\n",
      "|17300|[pages, journal, ...| 16|  0.0715859|\n",
      "|17301|[mumbai, india, b...| 17| 0.07328072|\n",
      "|17302|[baghdad, suicide...| 18|0.051321927|\n",
      "|17303|[sydney, australi...| 19|  0.0317757|\n",
      "+-----+--------------------+---+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#User Defined Function\n",
    "#New dataframe shows the 10 most similar articles to the reference article\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "def add_labels(indx):\n",
    "    return jaccard[indx] # indx here will start from zero\n",
    "\n",
    "labels_udf = udf(add_labels, FloatType())\n",
    "\n",
    "new_df = data_df.withColumn('Jaccard', labels_udf('Ind'))\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c352cc96-2f36-42a5-9d65-42f7c3a71923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_df.createOrReplaceTempView(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d33b10da-092d-4c4d-9023-2a35a0be8bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:==============>                                           (2 + 6) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|   ID|             Content|   Jaccard|\n",
      "+-----+--------------------+----------+\n",
      "|19176|[los, angeles, ho...|0.15965167|\n",
      "|18716|[raining, califor...|0.14714715|\n",
      "|69080|[el, ni, o, wane,...|0.13731825|\n",
      "|72730|[ve, written, qui...|0.13376835|\n",
      "|25667|[spate, extreme, ...|0.13364056|\n",
      "|46483|[storms, pummelin...|0.13297872|\n",
      "|26524|[nate, cohn, upsh...|0.13284133|\n",
      "|57158|[cnn, decade, ago...|0.13219285|\n",
      "|73373|[americans, conce...|0.13029316|\n",
      "|62617|[cnn, re, 2, degr...|0.12547052|\n",
      "+-----+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 10 Most Similar Articles\n",
    "spark.sql(\"SELECT ID, Content, Jaccard \\\n",
    "        FROM df \\\n",
    "        WHERE ID != 69716 \\\n",
    "        ORDER BY Jaccard DESC LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebad336-ba10-41e9-b949-8fe4e77544c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
